
# 明确分析目的
-  1、找出购买商品数量前十的国家
-  2、找出交易额前十的国家
-  3、公司在哪些月份的销售量比较好
-  4、客单价是多少
-  5、用户行为分析
-  6、基于FRM模型，对用户进行分类
-  7、退货订单分析

# 理解数据


```python
# 导入相关库
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly as py
import plotly.graph_objects as go
import csv
import os

pyplot = py.offline.plot

os.getcwd()
os.chdir("F:\DataSets\online_retail")

# 数据读入
online_data = pd.read_excel("online_retail_II.xlsx")

# 查看数据情况
online_data.shape
```


```python
online_data.head()
```


```python
online_data.info()
online_data.columns
```

# 数据清洗
## 缺失数据
### 统计缺失率


```python
# 统计缺失率
online_data.apply(lambda x: sum(x.isnull()) / len(x), axis=0)
```

- Description    0.005572  Description存在数据缺失的情况，缺失率约为0.56%，暂时无法进行填充
- Customer ID    0.205395  Customer ID存在数据缺失，缺失率20.5%

### 删除缺失值


```python
# 删除缺失值
df1 = online_data.dropna(how="any").copy()
df1.info()
```

## 转换数据类型


```python
# 转换数据类型
# 转换Customer ID的数据类型为str
df1["Customer_ID"] = df1["Customer ID"].astype(str)
df1.info()
df1.drop(labels="Customer ID", axis=1, inplace=True)
df1.info()
```

## 重复值处理


```python
df1 = df1.drop_duplicates()
```

## 处理日期型数据


```python
# 获取InvoiceDate日期部分
df1["InvoiceDate"] = df1["InvoiceDate"].dt.date
```

## 根据需要新建数列


```python
# 新建一个销售总金额的字段 销售金额 = 单价 * 数量
df1["T_Price"] = df1.apply(lambda x: x[3] * x[5], axis=1)
```

# 数据分析

## 目标1：找出购买商品数量前十的国家


```python
# 目标1：找出购买商品数量前十的国家
df1[df1["Quantity"] > 0].groupby("Country")["Quantity"].sum().sort_values(
    ascending=False).head(10)
```


```python
# 将结果可视化
quan_top_10 = df1[df1["Quantity"] > 0].groupby(
    "Country")["Quantity"].sum().sort_values(ascending=False).head(10)

trace_0 = go.Bar(x=quan_top_10.index.tolist(),
                 y=quan_top_10.values.tolist(),
                 opacity=0.4)
layout = go.Layout(title="商品交易量前十的国家", xaxis=dict(title="国家"))
fig = go.Figure(data=trace_0, layout=layout)
fig.show()
```

## 目标2：找出交易额前十的国家


```python
# 目标2：找出交易额前十的国家
df1[df1["T_Price"] > 0].groupby("Country")["T_Price"].sum().sort_values(
    ascending=False).head(10)
```


```python
# 将结果可视化
p_top_10 = df1[df1["T_Price"] > 0].groupby(
    "Country")["T_Price"].sum().sort_values(ascending=False).head(10)

trace_0 = go.Bar(x=p_top_10.index.tolist(),
                 y=p_top_10.values.tolist(),
                 opacity=0.4)
layout = go.Layout(title="商品交易额前十的国家", xaxis=dict(title="国家"))
fig = go.Figure(data=trace_0, layout=layout)
fig.show()
```

## 目标3：公司在哪些月份的销售量比较好


```python
# 目标3：公司在哪些月份的销售量比较好
df1["year"] = pd.to_datetime(df1["InvoiceDate"]).dt.year
df1.sample(10)
```


```python
# 本次数据含有2009、2010两年的销售情况
# 对这两年分别进行统计
df_09 = df1.where(df1["year"] == 2009).dropna(how="all").copy()
df_09.shape
```


```python
df_09.sample(10)
```


```python
df_10 = df1.where(df1["year"] == 2010).dropna(how="all").copy()
df_10.shape
```

09年数据量较少,仅45000行，10年数据有477533


```python
df_09["month"] = pd.to_datetime(df1["InvoiceDate"]).dt.month
df_09[df_09["Quantity"] > 0].groupby(
    "month")["Quantity"].sum().sort_values(ascending=False)
```

我们可以得知，09年仅有12月的交易信息，无法得知其他月份信息，故无法进行比较


```python
df_10["month"] = pd.to_datetime(df1["InvoiceDate"]).dt.month
df_10[df_10["Quantity"] > 0].groupby("month")["Quantity"].sum().sort_values(
    ascending=False)
```


```python
df1["InvoiceDate"].sort_values().head(5)
```


```python
df_09["InvoiceDate"].sort_values(ascending=False).head(2)
```

09年数据自12-09 到12-23


```python
df_10["InvoiceDate"].sort_values().head(2)
```


```python
df_10["InvoiceDate"].sort_values(ascending=False).head(2)
```

10年数据自 01-04 到 12-09



 观察各月份产品交易数量，发现12月份统计数量明显偏低，分析原因可能是因为12月信息统计不充分，考虑将09年12月数据填充至10年



```python
df1["month"] = pd.to_datetime(df1["InvoiceDate"]).dt.month
df1[df1["Quantity"] > 0].groupby("month")["Quantity"].sum().sort_values(
    ascending=False)
```

绘制图形


```python
# 绘制图形
x1 = df1[df1["Quantity"] > 0].groupby("month")["Quantity"].sum().sort_values(
    ascending=False)
trace_0 = go.Bar(x=x1.index.tolist(),
                 y=x1.values.tolist(),
                 marker=dict(opacity=0.8))
layout = go.Layout(title="各月份商品交易数量", xaxis=dict(title="月份"))
fig = go.Figure(data=trace_0, layout=layout)
fig.show()
```


```python
x2 = df1[df1["T_Price"] > 0].groupby(
    "month")["T_Price"].sum().sort_values(ascending=False)
trace_0 = go.Bar(x=x2.index.tolist(), y=x2.values.tolist(),
                 marker=dict(opacity=0.8))
layout = go.Layout(title="各月份商品交易额", xaxis=dict(title="月份"))
fig = go.Figure(data=trace_0, layout=layout)
fig.show()
```

- 可以得到，交易额与交易数量两个角度均表明销售最佳的月份是11月，其次是12月，下半年优于上半年。

原因分析：可能是因为数据来自欧美，他们的重大节日在下半年较多，促销活动也较多

## 目标4：客单价是多少


```python
# 目标4：客单价是多少
# 客单价 = 成交金额 / 成交用户数
sum_price = df1[df1["Quantity"] > 0]["T_Price"].sum()
count_no = df1[df1["Quantity"] > 0].groupby(
    df1["Customer ID"]).count().shape[0]
avgPrice = sum_price / count_no
print(avgPrice)
```

计算得出，平均客单价为2047元

## 目标5：用户行为分析


```python
# 目标5：用户行为分析
# 从用户消费次数，用户消费金额，用户购买产品数量三个维度进行探讨
customer_c = df1[df1["Quantity"] > 0].groupby("Customer ID").agg({
    "Invoice":
    "nunique",
    "Quantity":
    np.sum,
    "T_Price":
    np.sum
})
customer_c.describe()
```

通过上诉统计信息我们可以得到：
- 近一年的时间里，客户平均消费频次为4次，消费次数最高的达到205次，大部分客户的消费频次都在5次以内
- 近一年的时间里，客户平均消费金额为2047，中位数为705.5原，消费金额最高的客户达到349164.35元，是我们需要重点关注的对象
- 从商品购买数量上看，大部分客户购买数量都在1000件以内

## 目标6：基于RFM模型，对用户进行分类
 对比分析不同用户群体在时间、地区等维度下的交易量、交易金额，根据分析结果提出优化建议


```python
# 目标6：基于RFM模型，对用户进行分类
# 前期我们对Customer ID存在的缺失数据进行了删除（缺失率20.5%）
# 我们对缺失的客户ID进行常值填充（也可类似之前做删除处理，看个人选择）
online_data.info()
```


```python
online_data.apply(lambda x: sum(x.isnull()) / len(x), axis=0)
```


```python
# 同上，删除Description缺失数据
df2 = online_data.dropna(subset=["Description"]).copy()
# Customer ID的缺失数据通过U填充（U:表示未知）
df2["Customer ID"] = df2["Customer ID"].fillna("U")
```

### 再次进行数据清洗

#### 转换Customer ID的数据类型为str


```python
# 转换Customer ID的数据类型为str
df2["Customer ID"] = df2["Customer ID"].astype(str)
df2.info()
```

#### 处理日期


```python
# 获取InvoiceDate日期部分
df2["InvoiceDate"] = df2["InvoiceDate"].dt.date
```


```python
# 新建年，月，日三个特征
# 获取InvoiceDate年份
df2["year"] = pd.to_datetime(df2["InvoiceDate"]).dt.year
# 获取InvoiceDate月份
df2["month"] = pd.to_datetime(df2["InvoiceDate"]).dt.month
# 获取InvoiceDate 日
df2["day"] = pd.to_datetime(df2["InvoiceDate"]).dt.day
```


```python
# 日期
df2["date"] = pd.to_datetime(df2["InvoiceDate"])
df2.drop(["InvoiceDate"], axis=1, inplace=True)
df2.info()
```


```python
df2.sample(5)
```

#### 新建字段


```python
# 新建一个销售总金额的字段 销售金额 = 单价 * 数量
df2["T_Price"] = df2["Quantity"] * df2["Price"]
```


```python
df2["T_Price"] 
```

#### 重复值处理


```python
# 重复值处理
df2 = df2.drop_duplicates()
```

#### 异常值处理


```python
# 异常值处理
df2.describe()
```


```python
# 商品数量、单价存在负值或0
# 商品数量
df2_1 = df2.loc[df2["Quantity"] <= 0]
df2_1.info()
```


```python
print("异常值占比：", df2_1.shape[0] / df2.shape[0])
```

可能是退货


```python
# 单价
df2_2 = df2.loc[df2["Price"] <= 0]
print("异常值占比：", df2_2.shape[0] / df2.shape[0])
```

异常值占比： 0.0014582811037771777


```python
df2_2["Price"].sample(2)
```


```python
df2_2["Price"].groupby(df2_2["Price"]).count()
```

单价为0的记录有759条，可能此类货品为赠品；为负的三条记录其Description均为Adjust bad debt


```python
# 剔除退货相关的数据
df3 = df2.loc[(df2["Quantity"] > 0) & (df2["Price"] > 0)]
```

#### R、F、M

构建RFM值，并查看RFM信息，设置阈值

#####  R


```python
# R
# 客户最近一次消费时间
R_value = df3.groupby("Customer ID")["date"].max()
# 计算出客户最后一次消费距离某个截至日期的天数（以所有客户中最近一次消费时间为基准）
R = (df3["date"].max() - R_value).dt.days
```


```python
R.describe()
```


```python
# 绘图
sns.set(style="darkgrid")
sns.distplot(R, bins=25)
```

##### F


```python
# 客户消费频率
F = df3.groupby("Customer ID")["Invoice"].nunique()
```


```python
F.describe()
```


```python
# 绘图
# 受客户ID未知U影响，我们只查看F<50的部分
sns.distplot(F[F < 50], bins=25)
```

##### M


```python
# 客户的消费金额
M = df3.groupby("Customer ID")["T_Price"].sum()
```


```python
M
```


```python
df3.info()
```


```python
# 同上受客户ID未知U影响，我们只查看M<10*(75% : 1.723450e+03)的部分
plt.hist(M[M < 1.723e+04], color="c", alpha=.8)
plt.show()
```


```python
# 查看金额在75%内的分布：
plt.hist(M[M < 1.73e+03], bins=100, color="c", alpha=.8)
plt.show()
```

可见，客户ID缺失值用U填充对RFM值影响较大，接下来考虑删除缺失值，重复上述过程


```python
# 剔除未知客户进行分析
df4 = df3[~(df3["Customer ID"] == "U")]
R1_value = df4.groupby("Customer ID")["date"].max()
R1 = (df4["date"].max() - R1_value).dt.days
F1 = df4.groupby("Customer ID")["Invoice"].nunique()
M1 = df4.groupby("Customer ID")["T_Price"].sum()
```


```python
R1.describe()
```


```python
plt.hist(R1, bins=25, color="c", alpha=.5)
plt.show()
```

从图形上看，去掉U效果好很多啊


```python
F1.describe()
```


```python
plt.hist(F1[F1 < 50], color="c", alpha=.5)
plt.show()
```


```python
M1.describe()
```


```python
plt.hist(M1, color="c", alpha=.5)
plt.show()
```


```python
# 存在最大值349164
plt.hist(M[M < 2000], bins=100, color="c", alpha=.5)
plt.show()
```


```python


```


```python

```

##### 用户分级


```python
# 用户分级
# bins
R_bins = [0, 25, 50, 100, 200, 400]
F_bins = [1, 2, 5, 10, 100, 300]
M_bins = [0, 300, 600, 2000, 10000, 500000]

# 离散化
R_score = pd.cut(R1, R_bins, labels=[5, 4, 3, 2, 1], right=False)
F_score = pd.cut(F1, F_bins, labels=[1, 2, 3, 4, 5], right=False)
M_score = pd.cut(M1, M_bins, labels=[1, 2, 3, 4, 5], right=False)

RFM = pd.concat([R_score, F_score, M_score], axis=1)
RFM.rename(columns={
    "date": "R_score",
    "Invoice": "F_score",
    "T_Price": "M_score"
},
           inplace=True)
RFM.head()
```

转换数据类型


```python
# 转换数据类型
RFM.info()
for i in ["R_score", "F_score", "M_score"]:
    RFM[i] = RFM[i].astype(float)
RFM.describe()
```

设定平均值为阈值，数值大于平均值这标记为“高”，小于均值标记为“低”


```python
# 设定平均值为阈值，数值大于平均值这标记为“高”，小于均值标记为“低”
RFM["R"] = np.where(RFM["R_score"] > 3.337199, "高", "低")
RFM["F"] = np.where(RFM["F_score"] > 2.039889, "高", "低")
RFM["M"] = np.where(RFM["M_score"] > 2.554267, "高", "低")
```


```python
RFM.sample(10)
```

拼接R、F、M


```python
# 拼接R、F、M
RFM["value"] = RFM["R"].str[:] + RFM["F"].str[:] + RFM["M"].str[:]
```

#### 定义分级函数


```python
# 定义分级函数
def grade(x):
    if x == "高高高":
        return "重要价值客户"
    elif x == "低高高":
        return "重要保持客户"
    elif x == "高低高":
        return "重要发展客户"
    elif x == "低低高":
        return "重要挽留客户"
    elif x == "高高低":
        return "一般价值客户"
    elif x == "低高低":
        return "一般保持客户"
    elif x == "高低低":
        return "一般发展客户"
    else:
        return "一般挽留客户"
```

#### 统计用户等级分布情况


```python
RFM["grade"] = RFM["value"].apply(grade)
RFM["grade"].value_counts()
```

#### 对结果可视化


```python
#  对结果可视化
trace_1 = go.Bar(x=RFM["grade"].value_counts().index.tolist(),
                 y=RFM["grade"].value_counts().values.tolist(),
                 opacity=.5)
layout = go.Layout(title="用户等级信息", xaxis=dict(title="用户等级标签"))
fig = go.Figure(data=trace_1, layout=layout)
fig.show()
```


```python
trace_2 = go.Pie(labels=RFM["grade"].value_counts().index.tolist(),
                 values=RFM["grade"].value_counts().values,
                 hole=0.35,
                 textfont=dict(size=12, color="white"))
layout = go.Layout(title="用户等级比例")
fig = go.Figure(data=trace_2, layout=layout)
fig.show()
```

## 目标7：退货订单分析


```python
# 7、退货订单分析
# 退货金额合计
r = pd.pivot_table(df2_1,
                   index=["year"],
                   columns=["month"],
                   values=["T_Price"],
                   aggfunc={"T_Price": np.sum},
                   margins=False)
r.fillna(0)
```


```python
# 计算退货率： 退货率 = 退货合计金额 / 总金额
# 总金额 (df3:剔除退货后的数据)
t = pd.pivot_table(df3,
                   index=["year"],
                   columns=["month"],
                   values=["T_Price"],
                   aggfunc={"T_Price": np.sum},
                   margins=False)
t.fillna(0)
```


```python
# 退货率
r_rate = round(-r / t * 100, 5)
r_rate = r_rate.fillna(0)
r_rate.reset_index(drop=True,inplace=True)
```


```python
r_rate
# r_rate.loc[1][:].tolist()
r_rate.loc[0].index.levels[1]
```


```python
#  对结果可视化
trace_1 = go.Bar(x=r_rate.loc[0].index.levels[1].tolist(),
                 y=r_rate.loc[0].tolist(),
                 opacity=.5,
                 name="2009年")
trace_2 = go.Bar(x=r_rate.loc[0].index.levels[1].tolist(),
                 y=r_rate.loc[1][:].tolist(),
                 opacity=.5,
                 name="2010年")
layout = go.Layout(title="退货信息",
                   xaxis=dict(title="月份"),
                   yaxis=dict(title="退货率（百分比）"))
fig = go.Figure(data=[trace_1, trace_2], layout=layout)
fig.show()
```

# 总结

- 交易量前十的国家及其交易量分别为：

| 国家  | 交易量 |
| ----- |:----- :|
| United Kingdom  | 4430926 |
| Denmark | 229690| 
| Netherlands  | 183679| 
| EIRE   |   181413| 
| France | 162048| 
|  Germany  | 108633| 
|  Sweden | 52417| 
|  Spain | 22841| 
|  Switzerland | 22255| 
|  Australia | 20189| 

- 交易额前十的国家及其交易金额分别为：

| 国家  | 交易额 |
| ----- |:----- :|
| United Kingdom  | 7.414756e+06 |
| EIRE | 3.560852e+05| 
| Netherlands | 2.687860e+05| 
| Germany| 2.023953e+05| 
| France|  1.462154e+05| 
| Sweden |  5.317139e+04| 
| Denmark |  5.090685e+04| 
| Spain | 4.760142e+04| 
| Switzerland | 4.392139e+04| 
| Australia| 3.144680e+04| 

- 从交易额与交易数量两个角度均表明该公司销售最佳的月份是11月，其次是12月，下半年优于上半年。
    原因分析：可能是因为数据来自欧美，他们的重大节日在下半年较多，促销活动也较多
- 在2009-12到2010-12期间：平均客单价为2047元
- 2010年近一年的时间里，客户平均消费频次为4次，消费次数最高的达到205次，大部分客户的消费频次都在5次以内
- 这一年的时间里，客户平均消费金额为2047，中位数为705.5原，消费金额最高的客户达到349164.35元，是我们需要重点关注的对象
- 从商品购买数量上看，大部分客户购买数量都在1000件以内
- 通过RFM模型，我们将用户分为了8各类别。该公司用户数量最多的为一般挽留客户与重要价值客户，占总用户数的51.3%，其次为重要挽留客户与一般发展客户，共占总用户数的30%。公司可以参考此用户等级及其所占占比策划营销活动，有助于提升活动效果及营销费用的利用率
- 从退货情况来看，10年12月退货率明显偏高，可参考该月份及上月销售情况及内外部因素综合考虑，分析退货率高的原因。（提供几个思考方向：产品本身，销售渠道，价格，是否是促销，售后等方面）


```python

```
